\section{More discussions on the two themes}
\label{sec:conclusion_compare}

Although the thesis mainly discussed new optimisation algorithms for approximate inference, the material was organised into two themes.
\begin{itemize}
\item[I] Unifying variational methods. (Chapters \ref{chap:background}, \ref{chap:factor_tying}, \ref{chap:vrbound}) \\
In this part of the thesis, we studied two main classes of variational algorithms, namely expectation propagation (EP) and variational inference (VI). The main contributions are the two novel frameworks: stochastic EP (Chapter \ref{chap:factor_tying}) and R{\'e}nyi divergence VI (Chapter \ref{chap:vrbound}). SEP significantly improves the memory efficiency of the EP-like algorithms, making them scalable to datasets comprising millions of instances. Extensions to the distributed SEP case further provide a highly flexible framework that unifies global and local approximation algorithms from an algorithmic perspective. Next we introduced the VR bound framework that enables the deployment of Monte Carlo methods for $\alpha$-divergence methods, provides both upper- and lower-bounds to the marginal likelihood, and again connects global and local approaches, but from an energy point of view.

\item[II] Wild approximate inference. (Chapters \ref{chap:wild}, \ref{chap:grad_approx}) \\
This theme presented a new research direction for approximate inference, with the goal of allowing \emph{arbitrarily} complex approximate posteriors to be deployed. In Chapter \ref{chap:wild}, I argued that the density evaluation requirement should be removed when designing Monte Carlo based approximate inference algorithms. I showed that this allows the use of very flexible $q$ distributions, and presented several examples of them. Later I wrote a generic guide for these designs, containing four different algorithmic options. One of the schemes (direct gradient approximation) was further developed in Chapter \ref{chap:grad_approx}, in which an initial experiment on meta-learning for approximate inference was presented.
\end{itemize}

The two themes were motivated in very different ways. The study of the unified frameworks aimed at developing new algorithms that both advance the understanding of existing variational methods, and adapt well to the application areas for Bayesian deep learning. All the discussions and comparisons in that part were based on one assumption: the candidate approximate distribution family $\mathcal{Q}$ is pre-defined, such as mean-field Gaussians. Indeed in the empirical studies we used implementations of almost the same set-up, except that we tuned a few of the algorithmic settings such as the $\alpha$ values and the number of MC samples $K$.

Wild approximate inference, on the other hand, encourages the use of very complex approximate distributions. There is no reason to expect an accurate approximation with a distribution that factorises in general, even when it is fitted using algorithms with elegant theoretical properties (like VI/EP studied in the first theme). However, instead of providing recipes for complex approximate distribution designs (see some recent examples in Appendix \ref{chap:optional}) which fit the existing algorithms, we made a bold move to developing algorithms that enable approximations of arbitrary form. By doing this, we allow the users to focus on the \emph{statistical properties} that they want to plant into the approximations, rather than the \emph{algorithmic tractability} aspects that restrict the flexibility of the $q$ distribution. 

Considering hyper-parameter optimisation, there is another notable difference between the two themes. For the first theme, we designed energy functions to allow training both the hyper-parameters and the $q$ distribution, where as for the second theme, we decoupled the algorithms for inference and learning.\footnote{Although for example the approximate maximum likelihood procedure does not require the inference optimisation to converge.} In this way, wild approximate inference is more in line with numerical integration methods like quadrature and Monte Carlo: all of them treat (approximate) Bayesian inference as a \emph{computational} task, and leave the learning procedure to hyper-parameter optimisation and potentially model selection. However, when compared to the VAE approach, it becomes harder to understand the interaction between the approximate inference results and the hyper-parameter updates. In this regard, the VR bound framework might be preferred, as both procedures are coupled, and can be analysed by examining the single loss function in use. We will continue the discussion on this matter in the next section.


Nevertheless, there is one important technique that has repeatedly been discussed in both themes: the Monte Carlo approximation method. It has been crucial to the recent success of Bayesian deep learning \citep{graves:practical2011, kingma:vae2014, rezende:vae2014, blundell:bnn2015, gal:uncertainty2016, li:amcmc2017}, as for deep neural networks most of the quantities that a Bayesian would like to compute are analytically intractable, even when using approximate posterior distributions with simple forms. In this thesis, except for SEP, the MC approximation is applied to all the other algorithms when performing empirical evaluations. Even SEP is compatible with Monte Carlo methods: when the moment matching step has no analytical solution, Monte Carlo methods can be deployed to estimate the sufficient statistics of the tilted distribution that are required for the update \citep{barthelme:abc2011, gelman:dep2014}. 

