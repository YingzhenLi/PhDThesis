\section{Summary}
\label{sec:conclusions}

We have presented the Stein gradient estimator as a novel generalisation to the score matching gradient estimator. With a focus on learning implicit models, we have empirically demonstrated the efficacy of the proposed estimator by showing state-of-the-art results on three canonical learning tasks: approximating gradient-free MCMC, meta-learning for approximate posterior samplers, and unsupervised learning for image generation. Future work will expand the understanding of gradient estimators in both theoretical and practical sides. Theoretical development will compare both the V-statistic and U-statistic Stein gradient estimators. Practical work will improve the sample efficiency of kernel estimators in high dimensions and develop fast yet accurate approximations to the matrix inversion part. Finally follow-up work will study the generalisation of the Stein gradient estimator to non-kernel settings and discrete distributions.